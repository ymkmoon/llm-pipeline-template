## í„°ë¯¸ë„ ì±„íŒ…
## python rag_chat.py

# rag_chat.py
import os
from langchain.chains import RetrievalQA
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from dotenv import load_dotenv

# ----------------------------
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# ----------------------------
load_dotenv()
DB_PATH = os.getenv("EMBEDDING_DB_PATH", "./data_collection_db")
LM_STUDIO_URL = os.getenv("LM_STUDIO_URL", "http://localhost:1234/v1")
LM_MODEL = os.getenv("LM_MODEL", "openai/gpt-oss-20b")

# ë©€í‹°ìŠ¤ë ˆë“œ ê´€ë ¨ ì„¤ì • (Segmentation fault ì˜ˆë°©)
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["OMP_NUM_THREADS"] = "1"

# ----------------------------
# ì„ë² ë”© & ë²¡í„° DB ë¡œë“œ
# ----------------------------
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
db = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
retriever = db.as_retriever(search_kwargs={"k": 3})  # kê°’ ê¸°ë³¸ 3, í•„ìš”ì‹œ ì¡°ì •

# ----------------------------
# LLM ì—°ê²° (LM Studio)
# ----------------------------
llm = ChatOpenAI(
    model=LM_MODEL,
    openai_api_key="not-needed",       # LM StudioëŠ” API key ë¶ˆí•„ìš”
    openai_api_base=LM_STUDIO_URL,
    temperature=0.0
)

# ----------------------------
# RAG QA ì²´ì¸ ìƒì„±
# ----------------------------
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=False
)

# ----------------------------
# ì•ˆì „í•œ í„°ë¯¸ë„ ì±„íŒ… ë£¨í”„
# ----------------------------
def main():
    print("ğŸ’¬ RAG Chat (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜) ì‹œì‘")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit', 'quit', 'ì¢…ë£Œ' ì…ë ¥")

    while True:
        try:
            query = input("\nì§ˆë¬¸: ").strip()
            if query.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
                print("ğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            if not query:
                print("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            result = qa.invoke({"query": query})
            print("ë‹µë³€:", result.get("result", "ë‹µë³€ ì—†ìŒ"))

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤ (Ctrl+C).")
            break
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ----------------------------
if __name__ == "__main__":
    main()