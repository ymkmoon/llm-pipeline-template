## í¬ë¡¤ë§ => ì„ë² ë”© DB ì €ì¥
## python crawl_and_index_blog.py

# crawl_and_index_blog.py
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
import gc
from tqdm import tqdm

# ====== ë¸”ë¡œê·¸ URL ======
BASE_URL = "https://ymkmoon.github.io"
TAG_URL = f"{BASE_URL}/tags/"

# ====== ì„¤ì • ======
BATCH_SIZE = 10
MAX_THREADS = 5

# ====== 1. ë¸”ë¡œê·¸ ê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ======
def get_blog_links(tag_url: str):
    res = requests.get(tag_url, timeout=10)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")
    links = []

    for a in soup.select("a"):
        href = a.get("href")
        if href and href.startswith("/"):
            if "/tags/" not in href:
                full_url = BASE_URL + href
                if full_url not in links:
                    links.append(full_url)
    return links

# ====== 2. ê°œë³„ ë¸”ë¡œê·¸ ê¸€ í¬ë¡¤ë§ ======
def get_blog_content(url: str):
    try:
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        title = soup.find("h1")
        title_text = title.get_text(strip=True) if title else "ì œëª© ì—†ìŒ"
        paragraphs = [p.get_text(strip=True) for p in soup.find_all("p")]
        content = "\n".join(paragraphs)
        return f"{title_text}\n{content}"
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {url} ({e})")
        return None

# ====== 3. ë²¡í„°DB ì €ì¥ ======
def save_batch_to_vectorstore(docs, db, start_idx=0):
    ids = [f"blog-{i+start_idx}" for i in range(len(docs))]
    db.add_texts(docs, ids=ids)
    docs.clear()
    gc.collect()

# ====== 4. ë©”ì¸ ì‹¤í–‰ ======
def main():
    print(f"ğŸ”¹ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘: {TAG_URL}")
    links = get_blog_links(TAG_URL)
    total_links = len(links)
    print(f"ì´ {total_links}ê°œì˜ ë¸”ë¡œê·¸ ê¸€ ë°œê²¬\n")

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )
    db = Chroma(persist_directory="./data_collection_db", embedding_function=embeddings)

    docs = []
    global_idx = 0

    # tqdm ì§„í–‰ë¥  ë°” ì ìš©
    with tqdm(total=total_links, desc="ë¸”ë¡œê·¸ í¬ë¡¤ë§", unit="ê¸€", ncols=100) as pbar:
        with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
            futures = {executor.submit(get_blog_content, link): link for link in links}

            for future in as_completed(futures):
                content = future.result()
                pbar.update(1)  # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸

                if content:
                    docs.append(content)

                if len(docs) >= BATCH_SIZE:
                    save_batch_to_vectorstore(docs, db, start_idx=global_idx)
                    global_idx += BATCH_SIZE
                    pbar.set_postfix_str(f"ë°°ì¹˜ ì €ì¥ ì™„ë£Œ ({global_idx}ë¬¸ì„œ)")

        # ë‚¨ì€ ê¸€ ì €ì¥
        if docs:
            save_batch_to_vectorstore(docs, db, start_idx=global_idx)
            global_idx += len(docs)
            print(f"ğŸ’¾ ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ (ì´ {global_idx}ë¬¸ì„œ)")

    print("\nâœ… ë¸”ë¡œê·¸ ì„ë² ë”© DB ì €ì¥ ì™„ë£Œ")

# ====== ì‹¤í–‰ ======
if __name__ == "__main__":
    main()
